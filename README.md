# Vol Street: A Quantitative Research Platform for Volatility Alpha

![Project Status: Active Development](https://img.shields.io/badge/status-active%20development-green)
![Language: Python](https://img.shields.io/badge/python-3.9+-blue.svg)
![Core Tech: XGBoost | Optuna | Genetic Algorithm](https://img.shields.io/badge/core%20tech-XGBoost%20|%20Optuna%20|%20GA-orange)
![Infrastructure: AWS | Lambda Labs](https://img.shields.io/badge/infrastructure-AWS%20|%20Lambda%20Labs-blueviolet)

**Note:** The source code for this project is private due to its proprietary nature. This repository serves as a showcase to document the architecture, methodology, and results of the research platform.

Vol Street is a cloud-native quantitative research and trading platform engineered to extract alpha from complex equity volatility derivatives. It integrates a sophisticated, end-to-end machine learning pipeline that uses a Genetic Algorithm for automated feature discovery and a walk-forward validation framework to build robust predictive models.

---

## Visual Showcase

The platform's output is a "confidence score" (0-100) indicating the model's conviction in a directional move over a defined forward period. The following are representative visualizations generated by the platform's analysis tools.

<p align="center">
  <em>Walk-Forward Out-of-Sample Equity Curve</em><br>
  <img src="images/equity_curve.png" width="700" alt="Walk-Forward Equity Curve of the Strategy">
</p>
<p align="center">
  <em>(Left) SHAP Summary Plot identifying top predictive features. (Right) Genetic Algorithm fitness evolution over generations.</em><br>
  <img src="images/shap_summary.png" width="400" alt="SHAP Feature Importance Plot">
  <img src="images/ga_fitness.png" width="400" alt="Genetic Algorithm Fitness Evolution">
</p>

---

## Research Philosophy & End-to-End Pipeline

The platform is built on a foundation of hypothesis-driven research and rigorous, automated validation to mitigate overfitting and discover genuine alpha.

### 1. Foundational Data Engineering
A comprehensive data pipeline first acquires and processes terabytes of historical data from multiple sources (IVolatility, CBOE, YFinance). It constructs a rich feature set including:
- Implied volatility surfaces and term structures (slope, curvature, skew).
- VIX futures contango/backwardation and roll yield.
- Backtested performance data from dozens of systematic options strategies (strangles, condors, etc.), turning strategy P&L itself into a feature.

### 2. Genetic Algorithm for Automated Feature Discovery
Instead of manual feature selection, a Genetic Algorithm (`xgb_genetic`) systematically evolves populations of feature sets over hundreds of generations. Each individual (a feature subset) is evaluated via a full walk-forward backtest, optimizing for a multi-objective fitness function that balances performance (e.g., Sharpe/Sortino Ratio) and model parsimony.

### 3. Robust Walk-Forward Validation
The core of the platform is a sophisticated walk-forward engine (`xgb_ga_wf.py`) that simulates real-world performance by:
- **Rolling GA Windows:** Periodically re-running the Genetic Algorithm on expanding windows of historical data to discover the optimal feature set for the current regime.
- **Out-of-Sample Testing:** Using the feature set discovered by the GA to train and optimize an XGBoost model, which is then tested on a subsequent, unseen "out-of-sample" period.
- **Hyperparameter Optimization:** Leveraging Optuna within each OOS period to find the best XGBoost hyperparameters, optimizing for a weighted objective of profit, risk-adjusted return, and directional accuracy.

### 4. Explainable AI (XAI) for Model Insight
To ensure models are not black boxes, SHAP (SHapley Additive exPlanations) analysis is integrated throughout the pipeline. This allows for deep inspection of feature contributions, validation of model behavior, and generation of new research hypotheses.

---

## System Architecture

The project is architected as a modular pipeline, separating data preprocessing, feature engineering, backtesting, GA optimization, and model validation into distinct, orchestrated components.

```mermaid
graph TD
    subgraph Data Layer
        A1[IVolatility API]
        A2[CBOE VIX Data]
        A3[YFinance OHLCV]
    end

    subgraph Preprocessing & Feature Engineering
        B[Data Pipelines]
        C{Options Backtesting Framework}
        D["Consolidated Feature Dataset (.parquet)"]
    end
    
    subgraph Machine Learning Core
        E[Walk-Forward Orchestrator]
        F{Genetic Algorithm}
        G["XGBoost Classifier w/ Optuna"]
        H[Out-of-Sample Predictions]
    end
    
    subgraph Analysis & Output
        I[Combined Equity Curve]
        J["Performance Metrics & SHAP Analysis"]
        K[Final Confidence Score]
    end

    A1 --> B
    A2 --> B
    A3 --> B
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G
    G --> F
    G --> H
    H --> I
    H --> J
    I --> K
    J --> K