Vol Street: A Quantitative Research Platform for Volatility Alpha
Note: The source code for this project is private due to its proprietary nature. This repository serves as a showcase to document the architecture, methodology, and results of the research platform.

Vol Street is a cloud-native quantitative research and trading platform engineered to extract alpha from complex equity volatility derivatives. It integrates a sophisticated, end-to-end machine learning pipeline that uses a Genetic Algorithm for automated feature discovery and a walk-forward validation framework to build robust predictive models.

Visual Showcase
The platform's output is a "confidence score" (0-100) indicating the model's conviction in a directional move over a defined forward period. The following are representative visualizations generated by the platform's analysis tools.

&lt;p align="center">
&lt;em>Walk-Forward Out-of-Sample Equity Curve&lt;/em>&lt;br>
&lt;img src="https.../equity_curve.png" width="700" alt="Walk-Forward Equity Curve of the Strategy">
&lt;/p>
&lt;p align="center">
&lt;em>(Left) SHAP Summary Plot identifying top predictive features. (Right) Genetic Algorithm fitness evolution over generations.&lt;/em>&lt;br>
&lt;img src="https.../shap_summary.png" width="400" alt="SHAP Feature Importance Plot">
&lt;img src="https.../ga_fitness.png" width="400" alt="Genetic Algorithm Fitness Evolution">
&lt;/p>

Research Philosophy & End-to-End Pipeline
The platform is built on a foundation of hypothesis-driven research and rigorous, automated validation to mitigate overfitting and discover genuine alpha.

1. Foundational Data Engineering
A comprehensive data pipeline first acquires and processes terabytes of historical data from multiple sources (IVolatility, CBOE, YFinance). It constructs a rich feature set including:

Implied volatility surfaces and term structures (slope, curvature, skew).
VIX futures contango/backwardation and roll yield.
Backtested performance data from dozens of systematic options strategies (strangles, condors, etc.), turning strategy P&amp;L itself into a feature.
2. Genetic Algorithm for Automated Feature Discovery
Instead of manual feature selection, a Genetic Algorithm (xgb_genetic) systematically evolves populations of feature sets over hundreds of generations. Each individual (a feature subset) is evaluated via a full walk-forward backtest, optimizing for a multi-objective fitness function that balances performance (e.g., Sharpe/Sortino Ratio) and model parsimony.

3. Robust Walk-Forward Validation
The core of the platform is a sophisticated walk-forward engine (xgb_ga_wf.py) that simulates real-world performance by:

Rolling GA Windows: Periodically re-running the Genetic Algorithm on expanding windows of historical data to discover the optimal feature set for the current regime.
Out-of-Sample Testing: Using the feature set discovered by the GA to train and optimize an XGBoost model, which is then tested on a subsequent, unseen "out-of-sample" period.
Hyperparameter Optimization: Leveraging Optuna within each OOS period to find the best XGBoost hyperparameters, optimizing for a weighted objective of profit, risk-adjusted return, and directional accuracy.
4. Explainable AI (XAI) for Model Insight
To ensure models are not black boxes, SHAP (SHapley Additive exPlanations) analysis is integrated throughout the pipeline. This allows for deep inspection of feature contributions, validation of model behavior, and generation of new research hypotheses.

System Architecture
The project is architected as a modular pipeline, separating data preprocessing, feature engineering, backtesting, GA optimization, and model validation into distinct, orchestrated components.

Code snippet

graph TD
    subgraph Data Layer
        A1[IVolatility API]
        A2[CBOE VIX Data]
        A3[YFinance OHLCV]
    end

    subgraph Preprocessing & Feature Engineering
        B[Data Pipelines] --> C{Options Backtesting Framework}
        A1 & A2 & A3 --> B
        C --> D[Consolidated Feature Dataset (.parquet)]
    end
    
    subgraph Machine Learning Core
        E[Walk-Forward Orchestrator] --> F{Genetic Algorithm}
        D --> E
        F --> G[XGBoost Classifier w/ Optuna]
        G --> F
        G --> H[Out-of-Sample Predictions]
    end
    
    subgraph Analysis & Output
        H --> I[Combined Equity Curve]
        H --> J[Performance Metrics & SHAP Analysis]
        I & J --> K[Final Confidence Score]
    end
&lt;details>
&lt;summary>&lt;b>Technical Deep Dive: Key Code Components&lt;/b>&lt;/summary>

utils/run_all_pipelines.py: Orchestrator for the initial data ingestion and feature creation. It runs modules for IV surface generation, VIX term structure analysis, and options strategy backtesting to create the foundational dataset.
xgb_models/xgb_ga_wf.py: The master script for the entire walk-forward validation process. It generates rolling time windows, invokes the Genetic Algorithm for each window, and then runs the out-of-sample XGBoost backtest on the resulting best features.
xgb_genetic/feature_optimizer.py: The core Genetic Algorithm engine. It manages populations of feature sets, parallelizes fitness evaluations using Dask, and applies genetic operators (crossover, mutation) to evolve optimal solutions.
xgb_classifier/run_classifier.py: The main entry point for running a single, complete XGBoost backtest. It is called repeatedly by the GA to evaluate individuals and by the walk-forward orchestrator to test the final feature sets.
xgb_classifier/train_and_forecast.py: The computational heart of the backtester. It handles the detailed walk-forward logic (rolling/expanding windows), feature scaling, model training, prediction, and signal generation based on confidence thresholds.
xgb_classifier/optuna_tuning.py: Implements the hyperparameter search using Optuna. It defines a complex objective function that can be weighted to optimize for Sortino ratio, profit, and other financial metrics.
Visualization & Analysis Tools (visualize_ga_umap.py, genetic_plotter.py): A suite of tools using Plotly and UMAP for deep, interactive analysis of the GA's optimization landscape and the final model's performance.
&lt;/details>